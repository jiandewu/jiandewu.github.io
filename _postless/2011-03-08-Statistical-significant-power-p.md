---
layout: post
title: 统计学假设检验中显著性水平α, 检验力power, p值的含义
tags: 统计学, 数学
categories: 数学
public: false
---
## 显著性水平 α
就是你允许最多有多大比例 `H0` 通过你的测试——你允许最多有多大比例 `H0` 被你误以为是 `H1` 。这是预先设置好的，在研究前就存在的。

显著性水平α(significance level)=1-置信水平(confidence level)

## 检验力 power
就是你的测试能够让多大比例 `H1` 通过——你有多大能力发现 `H1` 是 `H1` 。检验力分两种，一种是事前检验力，即在正式进行研究前，你预先设定一个检验力标准，为了获得这么大的检验力，你需要对研究进行一些设计；另一种是回溯性检验力，即在研究进行之后，根据结果计算自己在研究中实际拥有的检验力。

## p 值
我的理解则是实际上你让 `H0` 之中的多大比例以为是 `H1`。

一般研究人员将他们想要推翻的结论作为 `null hypothesis (H0)`. `p` 值就是在 `null hypothesis` 成立的情况下，出现与实际观察结果相同或更坏的概率。`p` 值越小，成功证明 `null hypothesis` 不成立的可能性就越大。但我们不能利用 `p` 值通过反向推导认为 `H1` 成立。

## 置信区间
我们平常使用的频率学派（frequentist）95% 置信区间的意思并不是真值在这个区间内的概率是 95%。真值要么在，要么不在。由于在频率学派当中，真值是一个常数，而非随机变量（后者是贝叶斯学派） ，所以我们不对真值做概率描述。对于这个问题来说，理解的关键是我们是对这个构造置信区间的方法做概率描述，而非真值，也非我们算得的这个区间本身。

换言之，我们可以说，如果我们重复取样，每次取样后都用这个方法构造置信区间，有 95% 的置信区间会包含真值 (*)。然而（在频率学派当中）我们无法讨论其中某一个置信区间包含真值的概率。

只有贝叶斯学派才会说某个特定的区间包含真值的概率是多少，但这需要我们为真值假设一个先验概率分布（prior distribution）。这不适用于我们平常使用的基于频率学派的置信区间构造方法。

换种方法说，假设我们还没有取样，但已经制定好取样后构造 95% 置信区间的方法。我们可以说取样一次以后，获得的那个置信区间（现在还不知道）包含真值的概率是 95%。然而在取样并得到具体的一个区间之后，在频率学派框架下就无法讨论这个区间包含真值的概率了。

取样前能讨论，取样后却无法讨论，这可能让很多人感到很不自然。扩大来说，传统频率学派对已经发生，但我们不知道结果的事件的讨论存在困难。虽然这个问题通常在应用上无伤大雅，但确实有不少学者因此寻求对概率的不同解释。
[//]: # (https://www.zhihu.com/question/26419030/answer/67765631?utm_campaign=webshare&)

很多自称搞统计的人也理解错误，就是怎么解释置信区间呢？

比如给定一组参数，算出来总体平均值的置信区间[a,b]，是不是说总体平均值有95%的概率在这个区间内？这样理解是逻辑混乱的结果，没搞懂什么是常数，什么是随机变量这些基本问题。

首先，总体参数，是一个常数，只是你不知道，是unknown constant，不知道不代表随机，完全两个概念。然后，一旦估计出区间，这区间也是确定的，参数也是确定的，不存在任何随机问题，那么现在大家应该清楚答案最开始说对置信区间最大的误解”<u>95%置信区间有95%的概率包括真实参数</u>“的问题在哪了。

那么正确的解释是怎样的？可以有很多种，这里直说一个解释：<b>95%置信区间，意味着如果你用同样的步骤，去选样本，计算置信区间，那么100次这样的独立过程，有95%的概率你算出来的区间可以包括真实参数值。</b>

实际科学工作中，通常约定多个标准，比如3-sigma 代表 evidence，5-sigma 代表discovery。有时，在实验结果匮乏的时候，2-sigma 的结果也会称为 implication。

## 一类错误，二类错误
一类错误是拒绝实际是正确的假设，即“弃真”，二类错误是不拒绝实际上不成立的假设，即“存伪”

关于备择假设Ha和两类错误（以及似然比检验），是E. Pearson和J. Neyman在1928年发表在《生物计量》杂志上的文章中提出的概念，他们建立了与Pearson简单的p值系统不同的一套称作“假设检验”的理论体系。H0为真而拒绝的错误，称作I类错误，又称弃真错误、假阳性（false positive），和检验的显著水平（significancelevel），记作α；H0为假Ha为真而没能拒绝H0的错误，称作II类错误，又称存伪错误、假阴性（false negative）。而是否拒绝H0是将一次实验得到的统计量T0与事先确定的显著水平α相比较。

p值是Fisher先提出来的“显著性检验”理论体系中的概念：
1. 有一个命题，称之为”零假设“（null hypothesis）H0；
2. 找到一个统计量T，可以计算T的统计分布；
3. 一次试验结果可以计算得到一个确切的T值（T0），在H0成立的情况下，出现比T0更极端情况的概率值记作p值；
4. 如果p很小，则可以作为”零假设并不成立“的有力证据。

注意，在Fisher的这套体系里面不涉及备择假设Ha（alternative hypothesis）。

##

第二、关于P值的问题这里有一个观点，在茆诗松教授编著概率论和数理统计一书中说到，P值的定义为，在一次假设检验之中，利用观测值能够做出拒绝原假设的最小显著性水平。我觉得这句话是有道理的。将P值提出来，则在显著性的水平上面就可以直接进行显著性的检验，大大的提高了检验的效率；通过P值来判断显著性，虽然粗糙但是快捷，且并不与Neyman-Pearson假设检验相矛盾。若需要进一步的做判定，还是需要进行置信区间的估计。至于文章中提高的那位仁兄，做了两次试验发现P值的结果不一样，只能说明统计学的结论并不是绝对普世的，好比99%的把握与100%把握虽然只差了1%，但是性质的本质是有差别的。我见到过在一列将近100个的数据中，改动两个数据就能让数据的检验由显著变成不显著。所以严格来讲，P值的显著性并不是一锤定音的事情。

拒绝域的选择一直是颇有争议的。最初Fisher的显著性检验，是不需要拒绝域的，因此也就没有type II error。后来Neyman-Pearson强调了拒绝域在用数学处理假设检验中的重要性。现在我们熟知的假设检验，实际上是这两种思想的融合：一方面一个合法的test只需要满足type I error小于alpha，一方面真正好用的test又需要type II error尽量小。注意type II error的定义是和拒绝域的选择直接相关的。

###相关阅读
1. [Scientific method: Statistical errors](http://www.nature.com/news/scientific-method-statistical-errors-1.14700) 
[//]: # ([译]http://www.guokr.com/article/438043/)
1. [Confidence intervals are frequently misunderstood](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Confidence_interval%23Misunderstandings)
2. [P值之死](http://mp.weixin.qq.com/s?__biz=MjM5MDEzNDAyNQ==&mid=200652178&idx=1&sn=ebcfde94db2998f2bcf0407232d5c7c7&scene=2&from=timeline&isappinstalled=0#rd)